"""
å‹æµ‹è„šæœ¬ - 100/300/500 RPS ä¸‰æ¡£æµ‹è¯•
"""
import asyncio
import aiohttp
import time
import statistics
from concurrent.futures import ThreadPoolExecutor
import requests

API_URL = "http://localhost:8000/v1/strategy/query"
HEALTH_URL = "http://localhost:8000/health"

# æµ‹è¯•æ ·æœ¬
TEST_SAMPLES = [
    {
        "hand_id": "load_test",
        "table_id": "table_001",
        "street": "preflop",
        "hero_pos": "BTN",
        "effective_stack_bb": 100,
        "pot_bb": 1.5,
        "action_line": "FOLD_FOLD_FOLD_FOLD"
    }
] * 100  # 100ä¸ªæ ·æœ¬

def check_health():
    """æ£€æŸ¥APIå¥åº·çŠ¶æ€"""
    try:
        r = requests.get(HEALTH_URL, timeout=5)
        return r.status_code == 200
    except:
        return False

def single_request(payload):
    """å•æ¬¡è¯·æ±‚"""
    start = time.time()
    try:
        r = requests.post(API_URL, json=payload, timeout=10)
        latency = (time.time() - start) * 1000  # ms
        return {
            "status": r.status_code,
            "latency": latency,
            "success": r.status_code == 200 and r.json().get("success")
        }
    except Exception as e:
        return {
            "status": 0,
            "latency": (time.time() - start) * 1000,
            "success": False,
            "error": str(e)
        }

def run_load_test(rps, duration=30):
    """
    è¿è¡Œè´Ÿè½½æµ‹è¯•
    rps: ç›®æ ‡æ¯ç§’è¯·æ±‚æ•°
    duration: æµ‹è¯•æŒç»­æ—¶é—´(ç§’)
    """
    print(f"\n{'='*60}")
    print(f"è´Ÿè½½æµ‹è¯•: {rps} RPS, {duration}ç§’")
    print(f"{'='*60}")
    
    if not check_health():
        print("âŒ API æœªå¯åŠ¨ï¼Œè¯·å…ˆè¿è¡Œ ./start.sh")
        return
    
    results = []
    start_time = time.time()
    request_interval = 1.0 / rps
    
    with ThreadPoolExecutor(max_workers=rps*2) as executor:
        futures = []
        
        while time.time() - start_time < duration:
            for sample in TEST_SAMPLES[:rps]:
                future = executor.submit(single_request, sample)
                futures.append(future)
            
            time.sleep(request_interval)
            
            # æ”¶é›†å·²å®Œæˆçš„è¯·æ±‚
            done = [f for f in futures if f.done()]
            for f in done:
                results.append(f.result())
                futures.remove(f)
        
        # ç­‰å¾…å‰©ä½™è¯·æ±‚å®Œæˆ
        for f in futures:
            try:
                results.append(f.result(timeout=5))
            except:
                results.append({"success": False, "latency": 0})
    
    # è®¡ç®—æŒ‡æ ‡
    total = len(results)
    successes = [r for r in results if r.get("success")]
    errors = total - len(successes)
    latencies = [r["latency"] for r in successes if r.get("latency", 0) > 0]
    
    if not latencies:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚")
        return
    
    # æ’åºè®¡ç®—åˆ†ä½æ•°
    latencies.sort()
    p50 = latencies[int(len(latencies) * 0.5)]
    p95 = latencies[int(len(latencies) * 0.95)]
    p99 = latencies[int(len(latencies) * 0.99)]
    
    actual_duration = time.time() - start_time
    actual_rps = total / actual_duration
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"  æ€»è¯·æ±‚æ•°: {total}")
    print(f"  æˆåŠŸ: {len(successes)} ({len(successes)/total*100:.1f}%)")
    print(f"  é”™è¯¯: {errors} ({errors/total*100:.1f}%)")
    print(f"  å®é™…RPS: {actual_rps:.1f}")
    print(f"\nâ±ï¸  å»¶è¿Ÿ (ms):")
    print(f"  P50: {p50:.1f}")
    print(f"  P95: {p95:.1f}")
    print(f"  P99: {p99:.1f}")
    print(f"  Min: {min(latencies):.1f}")
    print(f"  Max: {max(latencies):.1f}")
    print(f"  Avg: {statistics.mean(latencies):.1f}")
    
    return {
        "rps_target": rps,
        "rps_actual": actual_rps,
        "total_requests": total,
        "success_rate": len(successes)/total,
        "error_rate": errors/total,
        "latency_p50": p50,
        "latency_p95": p95,
        "latency_p99": p99
    }

def main():
    """ä¸»å‡½æ•° - è¿è¡Œä¸‰æ¡£å‹æµ‹"""
    print("ğŸš€ GTO Strategy API å‹æµ‹å¼€å§‹")
    print("è¯·ç¡®ä¿ API å·²å¯åŠ¨: ./start.sh")
    
    results = []
    
    # 100 RPS
    result_100 = run_load_test(100, duration=30)
    if result_100:
        results.append(result_100)
    
    time.sleep(5)  # å†·å´
    
    # 300 RPS
    result_300 = run_load_test(300, duration=30)
    if result_300:
        results.append(result_300)
    
    time.sleep(5)  # å†·å´
    
    # 500 RPS
    result_500 = run_load_test(500, duration=30)
    if result_500:
        results.append(result_500)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_report(results)

def generate_report(results):
    """ç”Ÿæˆå‹æµ‹æŠ¥å‘Š"""
    report = """# å‹æµ‹æŠ¥å‘Š

## æµ‹è¯•ç¯å¢ƒ
- API: http://localhost:8000
- æµ‹è¯•æ—¶é—´: {timestamp}
- æµ‹è¯•å·¥å…·: Python requests + ThreadPoolExecutor

## æµ‹è¯•åœºæ™¯
POST /v1/strategy/query
- Payload: preflop BTN 100BB standard open
- æ¯é¡¹æµ‹è¯•æŒç»­ 30 ç§’

## ç»“æœæ±‡æ€»

| RPS | å®é™…RPS | æˆåŠŸç‡ | P50 (ms) | P95 (ms) | P99 (ms) |
|-----|---------|--------|----------|----------|----------|
""".format(timestamp=time.strftime("%Y-%m-%d %H:%M:%S"))
    
    for r in results:
        report += f"| {r['rps_target']} | {r['rps_actual']:.1f} | {r['success_rate']*100:.1f}% | {r['latency_p50']:.1f} | {r['latency_p95']:.1f} | {r['latency_p99']:.1f} |\n"
    
    report += """
## ç»“è®º

"""
    
    # æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç›®æ ‡
    for r in results:
        if r['latency_p95'] < 250:
            report += f"- âœ… {r['rps_target']} RPS: P95 {r['latency_p95']:.1f}ms < 250ms (è¾¾æ ‡)\n"
        else:
            report += f"- âŒ {r['rps_target']} RPS: P95 {r['latency_p95']:.1f}ms > 250ms (æœªè¾¾æ ‡)\n"
    
    report += """
## å»ºè®®

1. è‹¥ P95 > 250msï¼Œè€ƒè™‘ï¼š
   - å¢åŠ Redisè¿æ¥æ± 
   - å¯ç”¨APIç¼“å­˜
   - ä¼˜åŒ–åºåˆ—åŒ–é€»è¾‘

2. è‹¥é”™è¯¯ç‡ > 1%ï¼Œæ£€æŸ¥ï¼š
   - å¹¶å‘è¿æ¥æ•°é™åˆ¶
   - è¶…æ—¶é…ç½®
   - èµ„æºä½¿ç”¨ï¼ˆCPU/å†…å­˜ï¼‰
"""
    
    with open("docs/latency_report.md", "w") as f:
        f.write(report)
    
    print("\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: docs/latency_report.md")
    print(report)

if __name__ == "__main__":
    main()
